name: 'voc2012_semantic_segmentation_panet_vgg16'
task: 'semantic_segmentation'
input_dim: (3, 480, 480) # Input dim follows https://github.com/chenxi116/DeepLabv3.pytorch
num_classes: 21 # (20 annotated class + 1 background)
save_model: True

SYSTEM:
  use_cpu: False
  num_workers: 16

BACKBONE:
  network: 'panet_vgg16'
  pooling: False
  use_pretrained: True
  pretrained_path: "/data/pretrained_model/vgg16-397923af.pth"

CLASSIFIER:
  classifier: "seg_cos"
  SEGHEAD:
    use_bilinear_interpolation: True

LOSS:
  loss: 'semantic_nllloss'

DATASET:
  dataset: 'VOC2012_seg'
  cache_all_data: True
  TRANSFORM:
    TRAIN:
      transforms: ('normalize', )
      joint_transforms: ('joint_naive_resize',)
      TRANSFORMS_DETAILS:
        NORMALIZE:
          mean: (0.4700, 0.4468, 0.4076)
          sd: (0.2439, 0.2390, 0.2420)
        crop_size: (480, 480)
    TEST:
      transforms: ('normalize', )
      joint_transforms: ('joint_naive_resize', )
      TRANSFORMS_DETAILS:
        NORMALIZE:
          mean: (0.4700, 0.4468, 0.4076)
          sd: (0.2439, 0.2390, 0.2420)
        crop_size: (480, 480)

TRAIN:
  max_epochs: 30
  batch_size: 16
  initial_lr: 1e-3
  lr_scheduler: "step_down"
  step_down_gamma: 0.1
  step_down_on_epoch: [20]
  log_interval: 20
  OPTIMIZER:
    type: "SGD"
    momentum: 0.9
    weight_decay: 0.0001


TEST:
  batch_size: 1
